---
title: "Лабораторная работа №2. Предварительный анализ данных и модель регрессии"
author: "С.А.Суязова (Аксюк), [sa_aksyuk@guu.ru](mailto:sa_aksyuk@guu.ru)"
date: "`r format(Sys.time(), '%d %b, %Y')`"
tags: "R[^1], r-project, RStudio"  
output:
  word_document:
    reference_docx: ./Шаблон.docx
    toc: yes
---

Ключевые слова: R[^1], r-project, RStudio  

Примеры выполнены R версии `r paste0(R.version$major, '.', R.version$minor)`, «`r R.version$nickname`».  

Версия RStudio: 1.4.1717.  

Все ссылки действительны на 8 февраля 2021 г.  

Репозиторий с материалами к курсу: [github.com/aksyuk/R_data_glimpse](https://github.com/aksyuk/R_data_glimpse)   

Файл с макетом кода для этой практики: `.Labs/lab-02_before.R`    

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    comment = "#>",
    collapse = TRUE
)

# функция для форматирования чисел в тексте (2 знака после запятой)
comma <- function(x) {
    format(x, nsmall = 2, digits = 2, big.mark = ' ', decimal.mark = ',')
}

```

##### Новая страница    




# Лабораторная работа №2: Предварительный анализ данных и модель регрессии   



## Философия опрятных (tidy) данных   

\ \ \ \ \ Если вы уже работали со статистикой от сбора до презентации результатов анализа, то наверняка заметили, что 80% времени уходит на подготовку данных. Понятие "опрятных данных" было введено с целью упорядочить шаги по такой подготовке, сократить время, затрачиваемое на них, и облегчить дальнейший анализ. Этот процесс в западной литературе называется "data tidying", по-русски получается длиннее: "структурирование и приведение в порядок наборов данных" [^2]. Требования к опрятным данным очень похожи на требования третьей нормальной формы в базах данных:   

1. Каждая переменная формирует столбец.  

1. Каждое наблюдение формирует строку.  

1. Каждый тип единицы наблюдения формирует таблицу.   

\ \ \ \ \ К счастью, в R есть удобные средства структурирования данных -- они сгруппированы в коллекцию пакетов *tidyverse*. Пакеты из этой коллекции построены по принципу единой грамматики, в которой таблицы являются подлежащими, а действия над ними -- глаголами. Мы рассмотрим средства пакета `dplyr`: функции непосредственной манипуляции данными. Но для начала остановимся на важной детали -- правилах именования переменных.   

\ \ \ \ \ Формально в R действуют несколько ограничений на имена:

* имя должно начинаться с буквы;  

* имя должно содержать только буквы, цифры, подчёркивания и точки;   

* имя не должно совпадать с именами системных констант (`pi`);   

* крайне нежелательно совпадение имён пользовательских объектов с именами функций пакетов R.   

\ \ \ \ \ Но это ещё не всё. Хороший код не просто формально и стилистически верен, но и понятен. Поэтому содержательные имена -- хороший тон не только для переменных, но и для столбцов таблиц. Удачно подобранные имена ускоряют написание кода, однако слишком длинные могут сделать его нечитаемым. Так или иначе, выбираете вы содержательные имена или рискуете запутаться в переменных `my.val`, `my.val.1` и прочих случайных сочетаниях символов, главное -- действовать последовательно. Остановитесь на стиле написания имён, который нравится именно вам:    

`пишите_все_имена_в_змеином_регистре`  
`илиИспользуйтеВерблюжийРегистр`   
`далее.имена.в.основном.написаны.через.точки`  
`Только.не_используйтеВсеВперемешку`  

\ \ \ \ \ И помните, что люди из Google уже написали руководства по стилю программирования на всех языках программирования, в том числе и на R [^3].    



## Графические системы в R      

\ \ \ \ \ R предоставляет пользователю широкие графические возможности. Если говорить о визуализации количественных данных, то на данный момент в R существуют три основных графических системы, которые принципиально отличаются друг от друга [^4]:  

1. **Встроенная система «base»** [^5]. Построена по принципу конструктора: различные функции вызываются последовательно и дополняют график. При этом обязательно использование одной базовой функции, которая определяет тип графика и данные и создаёт область графика. Такими основными функциями являются, например, `plot()`, `boxplot()`, `curve()`.  

1. **Система «trellis»**, реализованная в пакете **«lattice»** [^6]. Была создана специально для изображения кросс-секционных данных и направлена в основном на создание графиков по категориям значений. В отличие от «base», подавляющее большинство графиков «lattice» строится вызовом одной функции, и после создания графика его сложно изменить, например, добавив подписи осей, и нельзя дополнить новой порцией точек или кривых. С другой стороны, графические параметры в «lattice» настроены заранее и оптимизированы для представления нескольких графиков на одной панели.   

3.	**Система «ggplot»** (пакет **«ggplot2»** [^7]). Реализует грамматику графиков, предложенную Леландом Уилкинсоном. График собирается как «предложение» из нескольких функций, первая из которых задаёт исходные данные («существительное»), вторая -- их представление («глагол»), остальные добавляют на график дополнительные слои («прилагательные»). Как и в «lattice», система автоматически управляет графическими параметрами. Также функции «ggplot2» могут трансформировать данные (например, шкалы показателей) и изменять их под различные координатные системы.   

\ \ \ \ \ Функции трёх графических систем не сочетаются друг с другом. Поэтому прежде чем строить график, стоит понять, какие принципы изображения необходимы в данном случае:     

1.	На начальной, разведочной, стадии анализа, для представления данных, не сгруппированных по категориям, подходит «base».  

1.	Система «lattice» поможет представить данные с переменными-факторами, представив графики по категориям на отдельных панелях.  

1.	Система «ggplot2» построит более сложные визуализации, например, с пересчётом в другие координаты; нанесёт данные на географическую карту; сохранит график со всеми настройками в виде отдельного объекта в рабочем пространстве R.  
\ \ \ \ \ В R существует много готовых функций на базе перечисленных пакетов, которые служат для создания специальных графиков. Некоторые из них:   

* мозаичные графики и графики ассоциаций для визуализации категориальных данных: пакет «vcd» [^8];   

* самоорганизующиеся карты Кохонена: пакет «kohonen» [^9];   

* «тепловые карты» для визуализации схожести объектов и результатов кластерного анализа: пакет «gplots» [^10];   

* интерактивные трёхмерные графики: пакет «rgl» [^11];   

* фазовые плоскости одно- и двумерных автономных систем дифференциальных уравнений: пакет «phaseR» [^12].   

\ \ \ \ \ Далее мы рассмотрим работу с графическими системами «lattice» и «ggplot2».   



## Предварительный анализ и визуализация данных по импорту за 2019 год    

\ \ \ \ \ Загрузим пакеты, которые понадобятся нам в этой лабораторной.   

```{r}
library('dplyr')            # функции манипуляции данными  
library('data.table')       # объект "таблица данных"
library('WDI')              # загрузка данных из базы Всемирного банка
library('ggplot2')          # графическая система ggplot2
library('lattice')          # графическая система lattice
library('GGally')           # матричные графики разброса

```


\ \ \ \ \ **Пример №1**. Используем данные импорта в Уругвай в 2019 году по коду 86: товары, связанные с железнодорожным транспортом. Рассчитаем описательные статистики и построим несколько графиков, чтобы посмотреть на данные в разрезе периодов времени (месяцы 2019 года) и группы стран географического региона "Латинская Америка и Карибский бассейн", к которой относится Уругвай.    


### Загрузка и очистка данных

\ \ \ \ \ Код ниже загружает данные из БД международной торговли <https://comtrade.un.org/>. Чтобы определить код страны, можно обратиться к справочнику по адресу <https://comtrade.un.org/Data/cache/partnerAreas.json> (ищем "Uruguay").  

```{r, eval = F}

# создаём директорию для данных, если она ещё не существует:
data.dir <- 'data'
if (!file.exists(data.dir)) dir.create(data.dir)

# создаём файл с логом загрузок, если он ещё не существует:
log.filename <- 'data/download.log'
if (!file.exists(log.filename)) file.create(log.filename)

# Загрузить из базы данных международной торговли статистику импорта за 2019
#  год (данные ежемесячные) по стране и кодам, указанным в варианте.
# функция, реализующая API (источник: UN COMTRADE)
source("https://raw.githubusercontent.com/aksyuk/R-data/master/API/comtrade_API.R")

# имя файла для сохранения
dest.file <- './data/comtrade_import-2019_raw.csv'
if (!file.exists(dest.file)) {
    # загрузить и сохранить файл 
    s1 <- get.Comtrade(r = 'all', p = '858',
                       ps = as.character(2019), freq = "M",
                       rg = '1', cc = '86',
                       fmt = 'csv')
    write.csv(s1$data, fileName, row.names = F)
    # сделать запись в лог
    write(paste('Файл', dest.file, 'загружен', Sys.time()), 
          file = log.filename, append = T)
}

```

\ \ \ \ \ Чтобы не превысить ограничение на загрузку по API базы данных, имеет смысл скачать статистику один раз, записать её на диск, а при повторном запуске скрипта загружать данные из сохранённого файла.   

```{r, eval = F}
# читаем загруженные данные
DF.01 <- read.csv(dest.file, stringsAsFactors = F)

```

```{r, include = F}
# читаем ранее загруженные данные
fileURL <- 'https://raw.githubusercontent.com/aksyuk/R_data_glimpse/main/Labs/data/comtrade_import-2019_raw.csv'
DF.01 <- read.csv(fileURL, stringsAsFactors = F)

```

\ \ \ \ \ Посмотрим на размерность, структуру фрейма данных и выведем имена столбцов.   

```{r}
dim(DF.01)
str(DF.01)
colnames(DF.01)

```

\ \ \ \ \ Как видно, в именах столбцов много точек: так R заменяет символы, которые не могут входить в имена переменных (в нашем случае, пробелы и символ доллара). Очистим заголовки фрейма от повторяющихся точек, а также от точек в конце имени столбца, используюя функцию `gsub()`, которая относится к семейству функций для поиска и замены символов в строках.   

\ \ \ \ \ В R для поиска и замены подстрок в символьных векторах служат функции:    

* `grep(<`*что_ищем*`>', <`*где_ищем*`>')` -- функция просматривает символьный вектор *<где ищем>* и возвращает номера тех элементов, в которых встречается подстрока *<что ищем>*.    

* `grep(<`*что_ищем*`>', <`*где_ищем*`>', value = T)` -- возвращает значения (аргумент value = TRUE) элементов, в которых встречается подстрока.  

* `grepl(<`*что_ищем*`>', <`*где_ищем*`>')` -- функция делает то же, что и `grep()`, однако возвращает логический вектор, элементы которого равны `TRUE`, если в соответствующем элементе символьного вектора встречается подстрока, и `FALSE` в противном случае.  

* `sub(<`*что_ищем*`>', <`*на_что_заменяем*`>', <`*где_ищем*`>')` -- функция замены первого вхождения подстроки на другую последовательность символов. Если второй аргумент пустой, подстрока будет удалена.  

* `gsub(<`*что_ищем*`>', <`*на_что_заменяем*`>', <`*где_ищем*`>')` -- то же, что и `sub()`, но ищет и заменяет все вхождения подстроки в исходной строке [^13].   

```{r}
# копируем имена в символьный вектор, чтобы ничего не испортить
nms <- colnames(DF.01)
# заменить серии из двух и более точек на одну
nms <- gsub('[.]+', '.', nms)
# убрать все хвостовые точки
nms <- gsub('[.]+$', '', nms)
# заменить US на USD
nms <- gsub('Trade.Value.US', 'Trade.Value.USD', nms)
# проверяем, что всё получилось, и заменяем имена столбцов
colnames(DF.01) <- nms
# результат обработки имён столбцов
colnames(DF.01)

```

\ \ \ \ \ Чтобы привести таблицу с данными к аккуратному виду, нам также понадобится убрать полностью пустые столбцы.  

```{r}
# делаем подсчёт пропусков по каждому столбцу
na.num <- sapply(DF.01, function(x) sum(is.na(x)))
na.num

# в каких столбцах все наблюдения пропущены?
col.remove <- na.num == nrow(DF.01)
names(col.remove)[col.remove == T] 

# уберём эти столбцы из таблицы
DF.01 <- DF.01[, !col.remove]
dim(DF.01)

```

\ \ \ \ \ Для удобства манипулирования данными, создадим из нашего фрейма `DF.01` объект `DT.import` типа "таблица данных" (`data.table`).   

```{r}
DT.import <- data.table(DF.01)

```

\ \ \ \ \ У объектов типа `data.table` есть несколько преимуществ перед обычными фреймами:   

1. Компактное отображение в консоли. Если число строк таблицы велико, будут автоматически показаны только часть верхних и нижних строк.    

2. Больше возможностей у оператора `[]`. В квадратных скобках можно делать более лаконичное присваивание столбцам таблицы, кроме того, чтобы обратиться к столбцу, не нужно заново писать имя таблицы и символ `$`.   

3. Специальные выражения для оператора квадратных скобок `[]`: например, можно подсчитать количество строк с помощью `.N`, найти индекс строк по условию с помощью `.I`, обратиться к подвыборке из таблицы с помощью `.SD`.   

\ \ \ \ \ Подробнее о работе с объектами `data.table` и функциями манипулирования данными из пакета `dplyr` см. в разделе "Дополнительно" данного руководства.   

\ \ \ \ \ Воспользуемся функцией `select()` для выбора только нужных столбцов таблицы.    

```{r}
# столбцы таблицы
colnames(DT.import)
# оставляем только нужные столбцы
DT.import <- select(DT.import, Year, Period, Trade.Flow, Reporter, Partner, 
                    Commodity.Code, Trade.Value.USD)

```

\ \ \ \ \ В этой таблице нет групп стран по регионам и уровню дохода. Присоединим их из справочника из пакета `WDI`.   

```{r}
# список стран из справочника БД Всемирного банка
DT.country <- data.table(WDI_data$country)
DT.country <- select(DT.country, iso2c, country, region, income)

```

\ \ \ \ \ Нам понадобятся категории для стран-поставщиков (столбец Reporter), поэтому изменим названия нужных столбцов, добавив к ним `'Reporter.'`.   

```{r}
# добавляем 'Reporter.' в названия столбцов с характеристиками стран,
#  чтобы отличать продавцов от покупателя
colnames(DT.country) <- paste0('Reporter.', colnames(DT.country))
# добавляем столбцы с группами стран-продавцов
DT.import <- merge(DT.import, DT.country, 
                   by.x = 'Reporter', by.y = 'Reporter.country')
colnames(DT.import)
dim(DT.import)

```

\ \ \ \ \ Наконец, последний этап очистки данных: перекодируем названия периодов времени (месяцев 2019 года), чтобы они не воспринимались как непрерывные числовые показатели, и легче воспринимались на графике. Из формата `ГГГГММ` сделаем формат `ГГГГ-ММ`, а затем изменим тип столбца на фактор (т.е. категориальную переменную с пронумерованными уникальными значениями).   

```{r}
# наконец, меняем формат периода времени с ГГГГММ на ГГГГ-ММ
DT.import[, Period := as.character(Period)]
DT.import[, Period := paste0(substr(Period, 1, 4), '-', substr(Period, 5, 7))]
DT.import[, Period := factor(Period, 
                             levels = paste0('2019-', formatC(1:12, width = 2, 
                                                              flag = '0')))]

```


### Описательные статистики и визуализация   

\ \ \ \ \ Для начала посмотрим, как работает функция `summary()` применительно к столбцам таблицы различных типов.   

```{r}
# описательные статистики по таблице данных
summary(DT.import)

```

\ \ \ \ \ Можно видеть, что для столбцов-факторов (`Period`) `summary()` выдаёт количество уникальных значений, для непрерывных количественных (`Trade.Value.USD`) считает описательные статистики, а для категориальных (например, `Reporter`) выдаёт только класс. При наличии пропусков в столбце `summary()` подсчитает их количество. Обратим внимание, что столбец `Commodity.Code` воспринят функцией как количественный, что неверно, поскольку код товара по гармонизированной классификации это не более чем уникальный код, как ИНН организации.  

\ \ \ \ \ Из всех столбцов нас интересует количественный `Trade.Value.USD`, поэтому имеет смысл посмотреть на его описательные статистики подробнее.  

```{r}
# описательные статистики по количественному показателю
summary(DT.import$Trade.Value.USD)

# суммарная стоимость импорта в Уругвай в 2019 году по коду 86
sum(DT.import$Trade.Value.USD)

```

\ \ \ \ \ Далее будем строить графики в разрезе регионов, поэтому стоит установить, к каким категориям стран относится интересующая нас страна – Уругвай.  

```{r}
# к каким категориям относится Уругвай
filter(DT.country, Reporter.country == 'Uruguay')

```


### График динамики (графическая система `lattice`)   

\ \ \ \ \ Посмотрим, как менялась стоимость поставок в Уругвай по коду товара 86 в течение 2019 год. Система `lattice` отличается тем, что для построения графика достаточно вызова одной функции, первый аргумент которой – формула взаимосвязи переменных. Построим несколько графиков динамики на одном полотне, по регионам, к которым относятся страны-поставщики.    

```{r}
# так получается неверное отображение данных
xyplot(Trade.Value.USD ~ Period | Reporter.region, data = DT.import,
       type = 'o')

```

\ \ \ \ \ Несмотря на то, что функция запсиана верно, график неверно отображает данные: можно видеть, что позиции перепутаны, и месяцы не идут последовательно. Чтобы это исправить, создадим набор данных специально под этот график, где агрегируем и отсортируем значения по месяцам и регионам.   

```{r}
# чтобы отразить динамику правильно, нужно агрегировать стоимость поставок
#  по периоду и по региону мира
group_by(DT.import, Period, Reporter.region) %>% 
    summarise(Trade.Value.USD = sum(Trade.Value.USD)) -> dt.plot.01

```

\ \ \ \ \ В этом коде мы объединили несколько функций в один вызов с помощью оператора потока `%>%`. Он позволяет визуально выстроить последовательность действий, и сократить код за счёт того, что возвращаемое значение предыдущей функции автоматически становится первым аргументом следующей функции. Кроме того, чтобы сохранить результат операций в таблицу `dt.plot.01`, мы использовали оператор присваивания слева направо `->`.    

\ \ \ \ \ Назовём столбцы в новом наборе данных по-русски, чтобы график читался без пояснений.   

```{r}
colnames(dt.plot.01)[colnames(dt.plot.01) == 'Reporter.region'] <- 
    'Регион.поставщика'
# для отображения на графиках называем столбцы по-русски
colnames(dt.plot.01)[colnames(dt.plot.01) == 'Period'] <- 'Месяц'
colnames(dt.plot.01)[colnames(dt.plot.01) == 'Trade.Value.USD'] <- 
    'Стоимость.поставок.долл'

# результат: набор данных для первого графика 
dt.plot.01

```

\ \ \ \ \ Теперь график будет выглядеть корректно (обратите внимание: изменился аргумент `data`).    

```{r}
# теперь получается верный график динамики 
xyplot(Стоимость.поставок.долл ~ Месяц | Регион.поставщика, data = dt.plot.01,
       type = 'o')

```


### Графики с долями (графическая система `ggplot2`)   

#### Круговая   

\ \ \ \ \ Графическая система `ggplot2` предлагает другой подход: здесь график получается как результат сложения вызовов неограниченного количества функций. На первом месте всегда стоит функция-подлежащее `ggplot()`, которая определяет источник данных и роли переменных. На втором – функция-сказуемое, которая указывает, какую геометрию для изображения данных следует использовать; названия функций-сказуемых начинаются с `geom_`. Наконец, далее идут разнообразные функции-дополнения, которые задают оформление графика. При этом функции-дополнения не всегда необходимы, поскольку даже по умолчанию `ggplot2` предлагает красивое оформление графиков.   

\ \ \ \ \ Для начала подготовим данные: теперь нам понадобятся данные, агрегированные только по региону страны-поставщика.  

```{r}
# готовим данные для второго графика
group_by(DT.import, Reporter.region) %>% 
    summarise(Trade.Value.USD = sum(Trade.Value.USD)) -> dt.plot.02
dt.plot.02$Trade.Value.share <- paste0(round(dt.plot.02$Trade.Value.USD / 
    sum(dt.plot.02$Trade.Value.USD) * 100, 1), '%')
# для отображения на графиках называем столбцы по-русски
colnames(dt.plot.02)[colnames(dt.plot.02) == 'Reporter.region'] <- 
    'Регион.поставщика'

# результат: набор данных для второго графика 
dt.plot.02

```

\ \ \ \ \ Круговые диаграммы это первый тип диаграмм в Excel, однако в продвинутом анализе данных они используются не так часто. Поэтому в `ggplot2` нет отдельной геометрии для круговой диаграммы, но можно взять столбчатую (bartplot) и "свернуть" её в полярных координатах.   

```{r}
# исходные данные для графика и роли столбцов (x пустой)
gp <- ggplot(data = dt.plot.02, aes(x = '', y = Trade.Value.USD,
                                    fill = Регион.поставщика,
                                    label = Trade.Value.share))
# добавляем геометрию: столбчатая диаграмма 
#  + полярные координаты, чтобы свернуть ряд данных в окружность
gp <- gp + geom_bar(stat = 'identity', width = 1) + coord_polar('y', start = 0)
gp

```

\ \ \ \ \ Поясним роли переменных в аргументе `aes` функции `ggplot()`:   

1. `x` – показатель, который играет роль координаты по горизонтали;   

1. `y` – показатель с координатами по вертикали;   

1. `fill` – показатель, в зависимости от значений которого точки, или сектора, или столбцы на графике будут отличаться цветом;   

1. `label` – показатель, значения которого будут играть роль подписей данных.  

\ \ \ \ \ Мы использовали только фукнцию-подлежащее и функцию-сказуемое (`geom_bar()`). На итоговом графике много ненужной информации: шкала по кругу, подписи осей. В то же время, не подписаны доли на секторах. Исправим это, добавив функции-дополнения.   

```{r}
# добавляем подписи секторов
gp <- gp + geom_text(size = 3, position = position_stack(vjust = 0.5))
# меняем палитру графика
gp <- gp + scale_fill_brewer(palette = 'Set2')
# добавляем заголовок
gp <- gp + ggtitle('Импорт в Уругвай в 2019 по коду 86')
# добавляем подпись под графиком
gp <- gp + labs(caption = 'Уругвай относится к региону "Latin America & Caribbean"')
# убираем разметку шкалы
gp <- gp + theme_void()
# отображаем график
gp

```

\ \ \ \ \ В таком виде график подходит для вставки в отчёт или в презентацию. В ходе настройки мы изменили в том числе палитру цветов (функция `scale_fill_brewer`). Посмотреть варианты палитр для различных типов данных можно, например, на странице: <https://www.r-graph-gallery.com/38-rcolorbrewers-palettes.html>.    

#### Столбчатая с долями и накоплением     

\ \ \ \ \ Используем агрегированные данные для первого графика, только теперь сопоставим доли и пересчитаем стоимость в тысячи долларов.   

```{r}
dt.plot.01$Стоимость.поставок.долл <- 
    round(dt.plot.01$Стоимость.поставок.долл / 1000, 1)
colnames(dt.plot.01)[colnames(dt.plot.01) == 'Стоимость.поставок.долл'] <- 
    'Стоимость.поставок.тыс.долл'

```

\ \ \ \ \ Полный код построения графика показан ниже. Благодаря функции `scale_x_discrete(drop = F)` на горизонтальной шкале графика будут отображены и те месяцы, в которые поставок по нашему коду товара не было.    

```{r}
gp <- ggplot(data = dt.plot.01, aes(x = Месяц, y = Стоимость.поставок.тыс.долл,
                                    fill = Регион.поставщика,
                                    label = Стоимость.поставок.тыс.долл))
# добавляем геометрию: столбчатая диаграмма, столбики друг на друге
gp <- gp + geom_bar(stat = 'identity')
# добавляем подписи значений
gp <- gp + geom_text(size = 3, position = position_stack(vjust = 0.5))
# настройки горизонтальной оси
gp <- gp + scale_x_discrete(drop = F)
# меняем палитру графика
gp <- gp + scale_fill_brewer(palette = 'Set2')
# разворачиваем подписи по горизонтальной оси на 90 градусов
gp <- gp + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
# добавляем заголовок
gp <- gp + ggtitle('Импорт в Уругвай по коду 86')
# отображаем график
gp

```


### Топ-5 стран-поставщиков   

\ \ \ \ \ На последнем шаге нашего дескриптивного анализа получим топ-5 стран-поставщиков по коду 86 в Уругвай в 2019 году. Для начала по всему множеству стран мира.   

```{r}
# по всем странам
group_by(DT.import, Reporter) %>% 
    summarise(Trade.Value.USD = sum(Trade.Value.USD)) %>% 
    arrange(-Trade.Value.USD) -> df.top
# первые 5 строк отсортированной таблицы
df.top[1:5, ]

```

\ \ \ \ \ Далее, посмотрим на топ-5 таких стран из географического региона Уругвая.   

```{r}
# по странам латиноамериканского региона
group_by(filter(DT.import, Reporter.region == 'Latin America & Caribbean'), 
         Reporter) %>% 
    summarise(Trade.Value.USD = sum(Trade.Value.USD)) %>% 
    arrange(-Trade.Value.USD) -> df.top.region
# первые 5 строк отсортированной таблицы
df.top.region[1:5, ]

```

\ \ \ \ \ Поскольку таких стран меньше 5, мы получили пустые строки в итоговой таблице. Чтобы этого не допустить, исправим последнюю строку:    

```{r}
# первые 5 строк (пустые не выводить)
df.top.region[1:min(nrow(df.top.region), 5), ]

```

\ \ \ \ \ Наконец, топ-5 (или сколько есть) стран-поставщиков из категории стран с высоким доходом:   

```{r}
# по странам с высоким доходом
group_by(filter(DT.import, Reporter.income == 'High income'), 
         Reporter) %>% 
    summarise(Trade.Value.USD = sum(Trade.Value.USD)) %>% 
    arrange(-Trade.Value.USD) -> df.top.income
# первые 5 строк отсортированной таблицы
df.top.income[1:min(nrow(df.top.income), 5), ]

```



## Построение линейных регрессионных моделей для рейтинга лёгкости ведения бизнеса       

\ \ \ \ \ **Пример №2**. Построим для стран с высоким и средне-высоким доходом (High income & Upper middle income) модели зависимости рейтинга лёгкости ведения бизнеса (это зависимая переменная, `IC.BUS.EASE.XQ` из базы Всемирного банка) от объясняющих показателей:     

* `NY.GDP.PCAP.CD` – валовой внутренний продукт на душу населения в текущих ценах, долларов США (GDP per capita, current US$);   

* `IC.REG.COST.PC.ZS` – затраты на создание бизнеса, % от валового национального дохода на душу населения (Cost of business start-up procedures, % of GNI per capita);  

* `IC.REG.DURS` – время на создание бизнеса, дней (Time required to start a business, days);   

* `IC.TAX.TOTL.CP.ZS` – налоговая нагрузка на бизнес, % от прибыли (Total tax and contribution rate, % of profit);  

* `IC.TAX.DURS` – время на выплату налогов, часов (Time to prepare and pay taxes, hours).    

\ \ \ \ \ Данные по всем старанам мы загрузили в лабораторной №1. Теперь сделаем выборку для решения нашеё задачи.   

```{r, eval = F}
# коды и названия показателей по странам
ind.names <- c('NY.GDP.PCAP.CD', 'IC.REG.COST.PC.ZS', 
               'IC.REG.DURS', 'IC.TAX.TOTL.CP.ZS', 
               'IC.TAX.DURS', 'IC.BUS.EASE.XQ')
ind.labels <- c('ВВП на душу, текущие цены, USD',
                'Затраты на создание бизнеса, % от ВНД на душу',
                'Время на создание бизнеса, дней', 
                'Налоговая нагрузка на бизнес, % от прибыли',
                'Время на выплату налогов, часов',
                'Рейтинг лёгкости ведения бизнеса')
names(ind.labels) <- ind.names

# читаем ранее скачанные данные за 2019 год
dest.file <- './data/wdi_2019.csv'
DT.wdi.2019 <- data.table(read.csv(dest.file, stringsAsFactors = F))

```

```{r, include = F}
# коды и названия показателей по странам
ind.names <- c('NY.GDP.PCAP.CD', 'IC.REG.COST.PC.ZS', 
               'IC.REG.DURS', 'IC.TAX.TOTL.CP.ZS', 
               'IC.TAX.DURS', 'IC.BUS.EASE.XQ')
ind.labels <- c('ВВП на душу, текущие цены, USD',
                'Затраты на создание бизнеса, % от ВНД на душу',
                'Время на создание бизнеса, дней', 
                'Налоговая нагрузка на бизнес, % от прибыли',
                'Время на выплату налогов, часов',
                'Рейтинг лёгкости ведения бизнеса')
names(ind.labels) <- ind.names

# читаем ранее скачанные данные за 2019 год
fileURL <- 'https://raw.githubusercontent.com/aksyuk/R_data_glimpse/main/Labs/data/wdi_2019.csv'
DT.wdi.2019 <- data.table(read.csv(fileURL, stringsAsFactors = F))

```

```{r}
# смотрим первые строки таблицы
head(DT.wdi.2019)
# и размерность таблицы
dim(DT.wdi.2019)

```

\ \ \ \ \ Чтобы отфильтровать страны по нужному уровню дохода, используем функцию `filter()` пакета `dplyr`.  

```{r}
# фильтруем страны по регионам из варианта
unique(DT.country$Reporter.income)
DT.wdi.2019 <- filter(DT.wdi.2019, 
                      income %in% c('High income', 'Upper middle income'))
# размерность отфильтрованной таблицы
dim(DT.wdi.2019)

```

\ \ \ \ \ Очистим данные от пропусков. Здесь мы сталкиваемся с интересным моментом: ISO код Намибии – "NA" – совпадает с обозначением, принятым в R для пропущенных наблюдений. Чтобы не потерять наблюдение, вручную заменим этот технический "пропуск" на текстовое значение `"NA"`.   

```{r}
# сколько пропусков в столбцах таблицы
sapply(DT.wdi.2019, function(x){sum(is.na(x))})

# код Намибии NA совпадает с меткой пропущенного наблюдения в R
DT.wdi.2019[is.na(DT.wdi.2019$iso2c), ]
# исправляем это
DT.wdi.2019[is.na(DT.wdi.2019$iso2c), iso2c := 'NA']

# убираем строки с пропусками
dim(DT.wdi.2019)
DT.wdi.2019 <- na.omit(DT.wdi.2019)
dim(DT.wdi.2019)

```

\ \ \ \ \ В итоге в этой категории стран мы не потеряли ни одного наблюдения. Прежде чем строить модели, сделаем дескриптивный анализ из двух шагов:   

1. Посчитаем коэффициенты вариации переменных по формуле $CV = \hat{s_x} / \bar{x} \cdot 100\%$ (т.е. среднеквадратическое отклонение показателя разделить на его среднее значение). Коэффициент вариации может принимать любое значение (в т.ч. больше 100% и меньше 0%). Он показывает, насколько данные неоднородны. Однородным считается показатель с $CV < 33\%$, однако у реальных данных допустимо использовать в моделях переменные c более высокими значениями. Значения $CV > 200\%$ могут считаться рекомендацией к логарифмированию показателя.   

2. Построим графики взаимного разброса переменных с парными линейными коэффициентами корреляции. Коэффициент корреляции лежит в пределах от -1 до 1 и показывает тесноту линейной взаимосвязи между двумя показателями. В линеной регрессии линейная связь между зависимой переменной и объясняющими должна быть значимой (значительно отличаться от 0 в большую или в меньшую сторону), а между объясняющими, наоборот, связь должна в идеале отсутствовать. Допускаются значимые линейные взаимосвязи между объясняющими переменными, если они не теснее связей с зависимой.    

\ \ \ \ \ Ниже показан расчёт описательных статистик и коэффициентов вариации.    

```{r}
# описательные статистики
summary(DT.wdi.2019[, ..ind.names])

# коэффициенты вариации
CV <- round(sapply(DT.wdi.2019[, ..ind.names], sd) / 
                sapply(DT.wdi.2019[, ..ind.names], mean) * 100, 1)
df.CV <- data.frame(Показатель = ind.labels[ind.names], Коэфф.вариации.прц = CV)
df.CV

```

\ \ \ \ \ Для нас важно, что коэффициент вариации для зависимой переменной `IC.BUS.EASE.XQ` не выше 100%. Больше всего вариация у `IC.REG.COST.PC.ZS`. На этом этапе мы не будем предпринимать дополнительных преобразований данных.   

\ \ \ \ \ Теперь построим графики разброса с рассчитаем коэффициенты корреляции, изобразив всё это на одном полотне функцией `ggpairs()`.   

```{r}
# строим графики взаимного разброса
ggpairs(DT.wdi.2019[, ..ind.names], lower = list(continuous = 'smooth'))

```

\ \ \ \ \ Мы получили матричный график, где коэффициенты корреляции находятся в правом верхнем треугольнике матрицы, по диагонали изображены графики функций плотности распределения, а в нижнем левом треугольнике изображены графики разброса с линиями регрессии.   

\ \ \ \ \ Проанализируем графики разброса. Чем ближе точки к прямой регрессии, тем теснее взаимосвязь между парой переменных: в заголовке столбца, в котором расположен график, и в заголовке строки. Посмотрим на нижнюю строку графиков, где по вертикали отложена зависимая переменная `IC.BUS.EASE.XQ` (заголовок строки). Теснее всего выглядит линейная связь на втором графике, и наоборот, самое разреженное облако точек видно на четвёртом. Соответствующие коэффициенты корреляции нужно искать в последнем столбце матрицы (заголовок столбца `IC.BUS.EASE.XQ`). Прежде всего, обратим внимание, что после каждого коэффициента стоят три звёздочки. Это указывает на их высокую значимость. Мы возьмём стандартный уровень значимости 0.05, следовательно будем считать значимым те коэффициенты, после которых стоит одна (значимость 0.05), две (значимость 0.01) или три звёздочки (значимость свыше 0.01). Итак, исходя из коэффициентов корреляции в последнем столбце матрицы, все объясняющие переменные можно включать в таблицу.    

\ \ \ \ \ Посмотрим на коэффициенты корреляции в других столбцах. Они отражают тесноту линейных связей между объясняющими переменными модели. Так, можно заметить, что корреляция между объясняющими `IC.REG.COST.PC.ZS` и `IC.REG.DURS` (0.477) значима и выше, чем значимая корреляция `IC.REG.DURS` с зависимой переменной `IC.BUS.EASE.XQ` (0.404), поэтому корректнее будет включить `IC.REG.COST.PC.ZS` и `IC.REG.DURS` по отдельности в две разные модели.    

```{r}
# модель 1
fit.1 <- lm(IC.BUS.EASE.XQ ~ . -IC.REG.COST.PC.ZS, 
            data = DT.wdi.2019[, ..ind.names])
summary(fit.1)

# модель 2
fit.2 <- lm(IC.BUS.EASE.XQ ~ . -IC.REG.DURS, 
            data = DT.wdi.2019[, ..ind.names])
summary(fit.2)

```

\ \ \ \ \ Сравним модели по скорректированным R-квадратам (Adjusted R-squared): у второй он выше (0.466 > 0.411). Но у второй модели один из параметров незначим на уровне 0.05: p-значение для `IC.TAX.TOTL.CP.ZS` больше 0.05, и в конце соответствующей строки с коэффициентом стоит не звёздочка, а точка. Исключим эту переменную из модели.   

```{r}
# модель 2, параметры значимы на уровне 0.05
fit.3 <- lm(IC.BUS.EASE.XQ ~ . -IC.REG.DURS -IC.TAX.TOTL.CP.ZS, 
            data = DT.wdi.2019[, ..ind.names])
summary(fit.3)

```

\ \ \ \ \ Теперь все параметры значимы на уровне 0.05. Дадим интерпретацию, учитывая смысл переменных и их единицы измерения:   

* коэффициент при `NY.GDP.PCAP.CD` равен -0.0006, следовательно, при увеличении валового внутреннего продукта на душу населения на 1 доллар позиция в рейтинге лёгкости ведения бизнеса уменьшится (т.к. коэффициент меньше нуля) на 0.0006. То есть с увеличением ВВП страна поднимается в рейтинге выше, и условия для бизнеса лучше. Это выглядит логично.   

* коэффициент при `IC.REG.COST.PC.ZS` равен 1.5951, следовательно, при увеличении затрат на создание бизнеса на 1% от ВНД на душу населения позиция в рейтинге лёгкости ведения бизнеса увеличится почти на 1.6. Таким образом, страна упадёт более чем на полторы позиции в рейтинге. Эта объясняющая переменная работает как барьер для ведения бизнеса, и интерпретация, опять же, выглядит логичной.      

* коэффициент при `IC.TAX.DURS` равен 0.057, следовательно, при увеличении время на создание бизнеса на 1 день позиция в рейтинге лёгкости ведения бизнеса увеличится на 0.057.   

\ \ \ \ \ Мы интерпретировали построенную модель и можем сказать, что, согласно статистике Всемирного банка, среди стран с высоким и средне-высоким доходом значимыми барьерами для ведения бизнеса являются:   

* затраты на создание бизнеса, выраженные в процентах от ВНД на душу населения;   

* время на создание бизнеса, в днях;   

* ВВП на душу населения.   

\ \ \ \ \ Из них государство может напрямую влиять только на второй.   


##### Новая страница    




# Индивидуальные задания на анализ данных    

1. Посчитать описательные статистики, построить дескриптивные графики на данных по импорту в страну, загруженных из базы данных UN COMTRADE в индивидуальном задании к первой лабораторной. Найти топ-5 стран-партнёров в целом по миру, а также внутри групп стран по региону и уровню дохода.  

2. Построить регрессионные модели для рейтинга простоты ведения бизнеса на данных по странам мира, загруженных с помощью пакета `WDI` в индивидуальном задании к первой лабораторной. Проанализировать взаимосвязи между показателями, оценить параметры моделей, проинтерпретировать параметры лучшей модели.

##### Новая страница    




# Дополнительная информация: работа с `data.table` и функциями пакета `dplyr` на примере данных по авиарейсам    

## Преобразование данных с помощью пакета `dplyr`   

\ \ \ \ \ **Пример №3** взят из книги "Язык R в задачах науки о данных" Х.Уикема и Г.Гроулмунда [^14]. Применим функции манипуляции данными из пакета `dplyr` к данным по `r comma(336776)` авиарейсам из аэропортов Нью-Йорка в 2013 году из пакета `nycflights13`.  

```{r paragraph-01-chunk-01, warning = F}
library('dplyr')            # функции манипуляции данными  
library('nycflights13')     # данные по авиарейсам из Нью-Йорка
library('data.table')          # объекты "таблица данных"

```

\ \ \ \ \ Пакет `dplyr` переписывает некоторые базовые функции, о чём R сообщает в консоль. Так, чтобы обратиться к исходной версии функции `filter()`, нужно использовать полное имя с указанием пространства имён её пакета: `stats::filter()`. Нужные нам данные записаны в таблице `flights`, посмотрим на её содержимое.  

```{r paragraph-01-chunk-02}
flights

```

\ \ \ \ \ Таблица `flights` -- это не фрейм данных, а объект класса *tibble*, или *тиббл-фрейм*. Это фреймы, оптимизированные для работы с пакетами *tidyverse*, и первое отличие, которое бросается в глаза -- удобное представление таблицы в консоли (причём нам даже не понадобилась функция, чтобы его получить). В третьей строке указаны псевдонимы для типов данных. Всего их семь:   

* `int` -- целые числа;  

* `dbl` -- Числа с плавающей точкой (вещественные);  

* `chr` -- символьные векторы (строки);  

* `dttm` -- дата + время;  

* `lgl` -- логические (`TRUE` и `FALSE`);  

* `fctr` -- факторы;  

* `date` -- даты.  

\ \ \ \ \ Основные функции пакета `dplyr`, которые являются глаголами манипулирования данными:   

* `filter()` -- выбор наблюдений по их значениям, т.е. отбор строк таблицы;  

* `select()` -- выбор переменных по их именам, т.е. отбор столбцов таблицы;  

* `arrange()` -- перестановка строк;  

* `mutate()` -- создание новых переменных из существующих столбцов таблицы;   

* `summarize()` -- агрегирование таблицы;   

* `group_by()` -- функция для группировки строк таблицы по заданному критерию, может использоваться со всеми вышеперечисленными функциями.   

\ \ \ \ \ Согласно философии `dplyr`, каждый глагол, преобразующий таблицу, подчиняется следующим принципам:   

* Первый аргумент -- фрейм данных.  

* Следующие аргументы, в качестве которых используются имена переменных без кавычек, описывают действия, которые должны быть выполнены с фреймом.   

* Результат -- новый фрейм данных.   

\ \ \ \ \ Обратите внимание: функции пакета `dplyr` никогда не изменяют входной набор данных (это один из принципов опрятной обработки), поэтому для сохранения результатов используйте присваивание `<-`.    


### Фильтруем строки с `filter()`   

\ \ \ \ \ Отберём все авиарейсы за 1 января:   

```{r paragraph-01-chunk-03}
filter(flights, month == 1, day == 1)

```

\ \ \ \ \ Предыдущая функция только вывела результаты в консоль. Команда с присваиванием создаст новый объект, но обойдётся без вывода результата. Иногда требуется сделать и то, и другое одновременно, и для этого функцию надо заключить в круглые скобки:   

```{r paragraph-01-chunk-04}
(jan.1 <- filter(flights, month == 1, day == 1))

```

\ \ \ \ \ В фильтре часто применяются сравнения с заданным числом. Первый тонкий момент связан с округлением, которое не делает компьютер, оперируя вещественными числами. Сравните:   

```{r paragraph-01-chunk-05}
sqrt(2) ^ 2 == 2       # без округления равенство не выполняется
near(sqrt(2) ^ 2, 2)   # а вот функция near() делает приближённое сравнение

```

\ \ \ \ \ Второй тонкий момент связан с использованием логических операторов (все они перечислены на Рис.1).   

![Рис.1. Логические операторы и соответствующие множества [^15]](./pics/transform-logical.png)

Сравните:   

```{r paragraph-01-chunk-06}
filter(flights, month == 11 | month == 12)   # рейсы в январе и декабре
filter(flights, month == 11 | 12)            # вся таблица
11 | 12                                      # вот почему

```

\ \ \ \ \ Вторая функция ничего не фильтрует, потому что операция `11 | 12` выполняется перед фильтрацией по значению, и с итоге мы ищем в столбце с номером месяца значение `r 11 | 12`. Положительные числовые значения из столбца `month` неявно преобразуются в `TRUE`, и потому на выходе мы получаем всю таблицу.    

\ \ \ \ \ Наш выбор -- более универсальная и безопасная конструкция `x %in% y` -- все значения вектора `x`, которые содержатся в векторе `y`:    

```{r paragraph-01-chunk-07}
filter(flights, month %in% c(11, 12))   # рейсы в январе и декабре

```

\ \ \ \ \ Если условия отбора определяются по нескольким столбцам, мы перечисляем их через запятую. Отберём все рейсы с задержкой и по прибытию, и по отправке не более двух часов.   

```{r paragraph-01-chunk-08}
filter(flights, arr_delay <= 120, dep_delay <= 120)

```

\ \ \ \ \ Ещё один момент связан с обработкой пропущенных значений (`NA`). Функция `filter()` включает в результат только те строки, у которых условие равно `TRUE`, т.е. исключаются и те строки, для которых условие не выполняется, и отсутствующие значения.   


### Переставляем строки с `arrange()`   

\ \ \ \ \ Функция `arrange()` используется для сортировке таблиц. Аргументы -- таблица и имена столбцов, по которым её надо отсортировать (по первому из них сортируем в первую очередь). Рейсы в порядке возрастания даты:   

```{r paragraph-01-chunk-09}
arrange(flights, year, month, day)     # по возрастанию даты

```

\ \ \ \ \ Рейсы в порядке убывания (функция `desc()`) задержки прибытия:   

```{r paragraph-01-chunk-10}
arrange(flights, desc(arr_delay))      # по убыванию задержки

```

\ \ \ \ \ Отсутствующие значения всегда будут в конце отсортированной таблицы:   

```{r paragraph-01-chunk-11}
df <- tibble(x = c(5, 2, NA))
arrange(df, x)

```


### Отбираем столбцы с `select()`   

\ \ \ \ \ Функция `select()` полезна тем, что её синтаксис гораздо короче, чем базовые конструкции с оператором квадратных скобок для фреймов. Кроме того, есть приятные бонусы, например, с именами столбцов работают операторы "минус" и "двоеточие".    

```{r paragraph-01-chunk-12}
# выбрать столбцы по имени year, month, day
select(flights, year, month, day)
# выбрать столбцы между year и day (включая их)
select(flights, year:day)
# выбрать столбцы кроме year и day (и кроме них)
select(flights, -(year:day))

```

\ \ \ \ \ Но ещё полезнее функции гибкого поиска по именам столбцов:  

* `starst_with('abc')` -- имена, которые начинаются на `'abc'`.  

* `ends_with('abc')` -- имена, которые заканчиваются на `'abc'`.  

* `contains('ijk')` -- имена, которые содержат `'ijk'`.  

* `matches('(.)\\1'` -- имена, соответствующие регулярному выражению.  

* `num_range('x', 1:3)` -- имена `x1`, `x2` и `x3`.  

```{r paragraph-01-chunk-13}
# столбцы, имена которых заканчиваются на 'delay' (задержка)
select(flights, ends_with('_delay'))

```

\ \ \ \ \ Иногда нужно всего лишь переставить в начало таблицы несколько столбцов, и перечислять имена остальных накладно. Здесь поможет вспомогательная функция `everything()`, которая означает "все остальные столбцы":    

```{r paragraph-01-chunk-14}
# переставить время рейса и время полёта в начало таблицы
select(flights, time_hour, air_time, everything())

```

\ \ \ \ \ Отметим, что функция `select()` не предназначена для переименовывания столбцов, поскольку все столбцы, не упомянутые в аргументах функции, выпадают. Для этого служит `rename()`:   

```{r paragraph-01-chunk-15}
# переименовать столбец с использованием змеиного регистра
(flights.mod <- rename(flights, tail_num = tailnum))
# убедимся, что столбец переименован
select(flights.mod, tail_num, everything())

```


### Добавляем новые столбцы с `mutate()`   

\ \ \ \ \ Функция `mutate()` добавляет новые переменные в конец набора данных, поэтому для наглядности сформируем таблицу поменьше:   

```{r paragraph-01-chunk-16}
(flights_sml <- select(flights, year:day, ends_with('delay'), 
                       distance, air_time))

```

\ \ \ \ \ Посчитаем время, которое удалось нагнать, т.е. разницу между задержкой прибытия и задержкой вылета (`gain`), и седнюю скорость полёта:   

```{r paragraph-01-chunk-17}
# нагнанное время и скорость
mutate(flights_sml, 
       gain = arr_delay - dep_delay,
       speed = distance / air_time * 60)

```

\ \ \ \ \ Рассчитаем, сколько времени рейсы в среднем нагоняли за час, воспользовавшись тем, что на только что созданные столбцы можно ссылаться:   

```{r paragraph-01-chunk-18}
mutate(flights_sml, 
       gain = arr_delay - dep_delay,
       hours = air_time / 60,
       gain_per_hour = gain / hours)

```

\ \ \ \ \ Если требуется сохранить только пересчитанные столбцы, используйте `transmute()`:    

```{r paragraph-01-chunk-19}
transmute(flights_sml, 
          gain = arr_delay - dep_delay,
          hours = air_time / 60,
          gain_per_hour = gain / hours)

```

\ \ \ \ \ При вычислении нового столбца можно также использовать функции агрегирования (`sum()`, `mean()`), логарифмирования (`log()`, `log2()`, `log10()`), модульной арифметики (операторы `%/%` и `%%`), смещения (`lag()`, `lead()`), ранжирования (`min_rank()`, `row_number()`, `cume_dist()`) -- и это далеко неполный список. Всё многообразие трансформаций охватить одним примером нельзя, поэтому просто скажем, что `mutate()` позволяет производить со столбцами преобразования любой сложности.    


### Агрегируем таблицу с `summarize()`   

\ \ \ \ \ Глагол `summarize()` сворачивает таблицу в одну строку (или в одну строку на каждую подвыборку по функции `group_by()`). Среднее время задержки вылета (пропуски выбрасываем):   

```{r paragraph-01-chunk-20}
summarize(flights, delay = mean(dep_delay, na.rm = T))

```

\ \ \ \ \ То же среднее время, но по датам:    

```{r paragraph-01-chunk-21}
by_day <- group_by(flights, year, month, day)
summarize(by_day, delay = mean(dep_delay, na.rm = T))

```

\ \ \ \ \ Создадим таблицу для сопоставления пункта назначения (нас интересуют континентальные рейсы, поэтому мы не будем учитывать Гонолулу) и среднего времени задержки рейса.   

```{r paragraph-01-chunk-22}
# группируем рейсы по пунктам назначения
by_dest <- group_by(flights, dest)
# по группам считаем число рейсов, средние расстояние и задержку прибытия
delay <- summarize(by_dest,
                   count = n(),
                   dist = mean(distance, na.rm = T),
                   delay = mean(arr_delay, na.rm = T))
# фильтруем строки: пункты с числом опозданий больше 20, кроме Гонолулу
(delay <- filter(delay, count > 20, dest != 'HNL'))

```

\ \ \ \ \ А теперь сделаем то же самое с использованием **каналов** `%>%`. Аналог оператора `%>%` в используемой нами грамматике обработки данных -- слово "затем". То, что стоит слева от канала `%>%`, передаётся функции, которая стоит справа. Функции можно сцеплять в один канал, как вагоны поезда.    

```{r paragraph-01-chunk-23}
(delays <- flights %>%
     group_by(dest) %>%
     summarize(count = n(),
              dist = mean(distance, na.rm = T),
              delay = mean(arr_delay, na.rm = T)) %>%
     filter(count > 20, dest != 'HNL'))

```

\ \ \ \ \ Обратите внимание: у функций-глаголов в канале отсутствует первый аргумент. Его роль для `group_by()` играет таблица `flights`, которая стоит слева от `%>%`, для `summarize()` -- таблица-результат функции `group_by()`, и так далее. В итоге каналы делают код более коротким и связным.    

\ \ \ \ \ В функции `summarize()` можно использовать в принципе любые агрегирующие операции. Особенно полезны следующие функции:   

* меры среднего: `mean(x)`, `median(x)`;   

* меры разброса: `sd(x)`, `IQR(x)`, `mad(x)`;   

* меры ранжирования: `min(x)`, `quantile(x, .25)`, `max(x)`;   

* порядковые меры: `first(x)`, `nth(x)`, `last(x)`;   

* счётчики: `n(x)`, `sum(!is.na(x))` (количество пропусков), `ndistinct()`;  

* количество и доли логических значений: `sum(x>0)`, `sum(x>0)/length(x)`.   


## Объекты для хранения больших таблиц: `data.table`    

\ \ \ \ \ В 2015 году был предложен новый тип объектов для хранения таблиц – data.table, или таблица данных [^16]. Этот объект наследует методы data.frame и добавляет к ним свои, направленные на более эффективное выполнение операций выборки, обновления, группировки данных. Кроме того, методы data.table написаны на C, поэтому работают гораздо быстрее, чем аналогичные у data.frame. Разница становится заметной при обработке массивов данных порядка миллионов строк. Есть бенчмарки, которые показывают, что операции группировки `data.table` выполняются быстрее, чем тиббл-таблиц средствами пакета `dplyr`, а также быстрее, чем средствами библиотеки `pandas` для Python [^17] [^18].       

\ \ \ \ \ Объекты типа `data.table` тоже имеют формат отображения в консоли, отличный от обычных фреймов данных. Он не такой подробный, как у тиббл-таблиц, но лаконичен и по-своему удобен, например, показывает первые и последние строки.   

```{r paragraph-02-chunk-01}
# объект типа data.table
DT.flights <- data.table(flights)
DT.flights

```

\ \ \ \ \ Поскольку `data.table` обычно используется для хранения больших таблиц, полезно просматривать список таблиц этого типа в оперативной памяти:    

```{r paragraph-02-chunk-02}
# вывести список таблиц в памяти
tables()

```

\ \ \ \ \ Обратим внимание на столбец "KEY": в объекты data.table можно добавлять ключевые столбцы и делать с их помощью операции пересечения и объединения по принципу SQL-запросов. Кроме того, ключи ускоряют обработку таких таблиц.   

\ \ \ \ \ Выборки строк из таблицы можно делать так же, как из фрейма: указывая их номера перед запятой в квадратных скобках после имени таблицы. Также можно применять условия на значения, т.е. использовать в квадратных скобках не номера строк, а логические векторы. Однако выбор столбцов уже не работает так, как с объектом `data.frame`. При работе с таблицами надо придерживаться следующего синтаксиса:   

`DF[<`*условие_на_строки*`>, <`*список_столбцов*>`, <`*условие_группировки*`>]`    

\ \ \ \ \ *Условие на строки* -- это логическое выражение. В таблицу войдёт те строки, для которых значение этого выражения равно `TRUE`.  

\ \ \ \ \ *Условие группировки* -- аргумент `by`, которому мы присваиваем название столбца без кавычек, либо список из названий нескольких. Аналогично функции `group_by()` из пакета `dplyr`, аргумент `by` делает подвыборки таблицы данных по всем уникальным значениям столбцов из условия группировки, поэтому нужно следить, чтобы эти столбцы содержали дискретные данные.   

\ \ \ \ \ В *списке столбцов* могут стоять конструкции, которые создают новые переменные, в том числе и довольно сложные, на базе функций `apply()`. Кроме того, в `data.table` применяются специальные выражения, которые начинаются с символа точки. Остановимся на них подробнее.   

* `.N` – числовой вектор длины 1, количество строк в группе;   

* `.SD` – это объект data.table, который содержит подвыборку исходной таблицы по каждой из групп, исключая группы по переменным, указанным в аргументе "by";  

* `.BY` – список единичных векторов, по одному на каждую группу в аргументе "by" (удобно, если группы заранее неизвестны);   

* `.I` – числовой вектор, который хранит номера строк в исходной таблице для каждого элемента в группе;   

* `.GRP` – числовой вектор длины 1, простой счётчик групп: 1 для первой группы, 2 для второй, и т.д [^19].

\ \ \ \ \ Повторим сложные трансформации таблицы рейсов, которые сделали выше средствами `dplyr`.   

```{r paragraph-02-chunk-03}
# делаем то же, что сделали средствами dplyr:
# группировка + агрегирование + фильтрация
delay.2 <- DT.flights[, list(count = .N, 
                             dist = mean(distance, na.rm = T),
                             delay = mean(arr_delay, na.rm = T)),
                      by = dest]
delay.2

```

\ \ \ \ \ Отметим, что в отличие от функций `dplyr`, этот способ выдаёт результирующую таблицу, не отсортированную по первому столбцу. Повторим пример с расчётом времени задержки, которое рейсы нагоняют за час полёта, учитывая, что новые столбцы нельзя использовать сразу:       

```{r paragraph-02-chunk-04}
# в data.frame нельзя сразу обращаться к новым столбцам
DT.flights[, list(gain = arr_delay - dep_delay,
                  hours = air_time / 60,
                  gain_per_hour = (arr_delay - dep_delay) / (air_time / 60))]

```

\ \ \ \ \ В данном случае результат аналогичен тому, что возвращает нам функция `transmute()`, т.е. мы видим только новые столбцы.   

\ \ \ \ \ Составим ещё одну конструкцию с использованием синтаксиса `data.table`. Пусть нас интересует среднее время задержки рейсов в пункт назначения `'DSM'` по месяцам. Насколько отличаются задержки по месяцам?   

```{r paragraph-02-chunk-05}
# отбор только наблюдений из группы, их усреднение и сортировка по убыванию
DT.flights.sml <- DT.flights[, list(month, arr_delay, dest)]
DT.flights.sml[dest == 'DSM', 
               list(count = .N,
                    mean_arr_delay_DSM = mean(arr_delay, na.rm = T)), 
               by = month][, .SD[order(-mean_arr_delay_DSM)]]

```

\ \ \ \ \ У нас получилась довольно нагруженная конструкция с двойным оператором квадратных скобок: к таблице применяется первый, а к результату -- следующий. Тем не менее, такой синтаксис гораздо лаконичнее стандартного для фреймов данных.   





[//]: # Концевые сноски

[^1]: R Core Team (2015). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL <https://www.R-project.org/>  

[^2]: Олег Замощин [@turegum](https://habr.com/users/turegum/). Data tidying: Подготовка наборов данных для анализа на конкретных примерах / habr.com, 24 января 2015. URL: <https://habr.com/ru/post/248741/>   

[^3]: Руководство по стилю программирования на R. URL: <https://drive.google.com/open?id=1zS-jyjokHEL_IjCPaKPPbrJU89VHzzae>   

[^4]: Roger D. Peng. Материалы курса «Exploratory Data Analysis» Университета Джонса Хопкинса на портале coursera.org, доступные в репозитории на github.com: <https://github.com/rdpeng/courses/tree/master/04_ExploratoryAnalysis>

[^5]: R Core Team (2015). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL: <https://www.R-project.org/>   

[^6]: Sarkar, Deepayan (2008) Lattice: Multivariate Data Visualization with R. Springer, New York. ISBN 978-0-387-75968-5   

[^7]: H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2009   

[^8]: Блог Р.Кабакова Quick-R: Visualizing Categorical Data. URL: <http://www.statmethods.net/advgraphs/mosaic.html>   

[^9]: Self-Organising Maps for Customer Segmentation using R / R-bloggers.com. URL: <http://www.r-bloggers.com/self-organising-maps-for-customer-segmentation-using-r/>   

[^10]: Sebastian Raschka. A short tutorial for decent heat maps in R. URL: <http://sebastianraschka.com/Articles/heatmaps_in_r.html>   

[^11]: Garrett Grolemund. Quick list of useful R packages / support.rstudio.com. URL: <https://support.rstudio.com/hc/en-us/articles/201057987-Quick-list-of-useful-R-packages>   

[^12]: Markus Gesmann. Phase plane analysis in R / magesblog.com. URL: <http://www.magesblog.com/2014/11/phase-plane-analysis-in-r.html>   

[^13]: Jeffrey Leek. Материалы курса "Getting and Cleaning Data" Университета Джонса Хопкинса на портале coursera.org, доступные в репозитории на github.com: <https://github.com/jtleek/modules/tree/master/03_GettingData>   

[^14]: Хэдли Уикем, Гарретт Гроулмунд, Язык R в задачах науки о данных. -- М.: Диалектика, 2018.  

[^15]: Репозиторий к книге "Язык R в задачах науки о данных". URL: <https://github.com/hadley/r4ds>   

[^16]: M Dowle, A Srinivasan, T Short, S Lianoglou with contributions from R Saporta and E Antonyan (2015). data.table: Extension of Data.frame. R package version 1.9.6. <https://CRAN.R-project.org/package=data.table>   

[^17]: <https://github.com/Rdatatable/data.table/wiki/Benchmarks-:-Grouping>   

[^18]: <https://rpubs.com/edwardcooper/data_table_benchmark>  

[^19]: M Dowle, A Srinivasan, T Short, S Lianoglou with contributions from R Saporta, E Antonyan. Package 'data.table' Reference Manual, September 19, 2015. URL: <https://cran.r-project.org/web/packages/data.table/data.table.pdf>   